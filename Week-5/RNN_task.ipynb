{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "--0YvqKNwctA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cfcee7ff-31f7-4c63-9e30-6a4eb0a19a32"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-02 10:53:43--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-02 10:53:43 (45.7 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ts7hr3vqKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a357ab1d-2cac-4528-a6f1-84d8edac0e5e"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or7vbKkHvqK4",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "sLJDeRh1vqK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbaebaa7-97a8-49f0-d40f-80c2fa430f6c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiaZDATLvqLC",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "pfpfBJvtvqLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "6rRDe0BnvqLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "dc0c3fec-9745-466b-e4bb-648eeeb387ec"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "_X6dlKltvqLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "7cf8390d-1904-4e65-eb14-376593ac3e93"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSPzW-zvqLU",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "Ae8DLGvVvqLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d0b94da-d58b-4b02-eae6-2656caa193be"
      },
      "source": [
        "tokens = [pad_token]+list(set([char for name in names for char in name]))\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHpi-QBovqLZ",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "fSkIUOuQvqLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id ={w:i for i,w in list(enumerate(tokens))}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_BsLswI59p5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "xgUYDX_yvqLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "c-HDmnw6vqLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "762ccf79-aba9-41f4-b464-a95dce73a0cb"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[12 45 50 46 49 46  6  1  0]\n",
            " [12 16  1 14 39 41  0  0  0]\n",
            " [12 33 39 51 30 30 51  6  0]\n",
            " [12 16 51 14  5 46  2  2  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwwEVaPdvqLw",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "Od4WyyyKvqLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c8f275c9-d5a4-4cce-8994-a26dffd6e20b"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "T6cDTM-AvqL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03088743-749f-474d-b360-8c4a51ba8d14"
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next =Dense(rnn_num_units,activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas =Dense(n_tokens,activation='softmax')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:59: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqluCTXmvqL5",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "9Mvv6ArsvqL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:,0,:]\n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h =concatenate([x_t_emb,h_t],axis=1)\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t3lQdVUvqMC",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "x3Ao1fUVvqMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjWD04nlvqMH",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "3jxhs0K5vqMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNT5q6HtvqML",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "fXvhpu71vqMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "154e49e1-1871-462e-e6f1-de86915555e2"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srooz8qvvqMS",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "urBwoNjKvqMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd056cbb-e081-4278-a9e1-d8e18208dcb2"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtUlvfc4vqMX",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "3ims28ewvqMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "3tY-ju0bvqMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "rCSmnw2GvqMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "26ce384e-48a1-4de8-e6e2-45f7548d4ea2"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Wesiree\n",
            " Chinli\n",
            " Meliy\n",
            " Chari\n",
            " Laoturie\n",
            " Gardo\n",
            " Ulse\n",
            " Carana\n",
            " Metto\n",
            " Ilale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "SnTq2eECvqMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "180577c4-7b8c-47e6-cb59-2ebbe8742c58"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpalt\n",
            " Trumpoa\n",
            " Trumppa\n",
            " Trumpese\n",
            " Trumpanne\n",
            " Trumpet\n",
            " Trumpa\n",
            " Trumpesi\n",
            " Trumpi\n",
            " Trumprebdn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1-HWG8_vqM0",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "QOpO0UFyvqM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "hjYSKS_WvqM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw9EFPatvqM8",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "sPKy2huTvqND",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "XIZFTCW-vqNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwSKQpOgvqNK",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "t9LHTN_mvqNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "Nq3oSiJ0vqNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}